@inproceedings{10.1117/12.2254389,
author = {Ekaterina Sirazitdinova and Thomas M. Deserno},
title = {{System design for 3D wound imaging using low-cost mobile devices}},
volume = {10138},
booktitle = {Medical Imaging 2017: Imaging Informatics for Healthcare, Research, and Applications},
editor = {Tessa S. Cook and Jianguo Zhang},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {1013810},
keywords = {wound imaging, 3D imaging, 3D registration, dense reconstruction, wound assessment, photographic documentation, 3D printing, color correction},
year = {2017},
doi = {10.1117/12.2254389},
URL = {https://doi.org/10.1117/12.2254389}
}

@INPROCEEDINGS{9666435,
  author={Parihar, Gunjan and Christopher, Jabez and Joyce, Y Suba and Lazarus, Y. Bakthasingh and Dayalan, Julie},
  booktitle={2021 IEEE 6th International Conference on Computing, Communication and Automation (ICCCA)}, 
  title={Measurement of Skin Test Wheals Using Image Segmentation Approaches}, 
  year={2021},
  volume={},
  number={},
  pages={395-400},
  keywords={Photography;Image segmentation;Automation;Shape;Medical information systems;Size measurement;Skin;Intradermal skin test;Medical Image Processing;Image segmentation;Feature Extraction},
  doi={10.1109/ICCCA52192.2021.9666435}}

@article{10.1371/journal.pone.0215240,
    doi = {10.1371/journal.pone.0215240},
    author = {Moayedi-Nia, Saeedeh AND Barss, Leila AND Oxlade, Olivia AND Valiquette, Chantal AND Ly, Mei-Xin AND Campbell, Jonathon R. AND Lan, Zhiyi AND Nsengiyumva, Placide AND Fregonese, Federica AND Lisboa Bastos, Mayara AND Sampath, Danielle AND Winters, Nicholas AND Menzies, Dick},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The mTST – An mHealth approach for training and quality assurance of tuberculin skin test administration and reading},
    year = {2019},
    month = {04},
    volume = {14},
    url = {https://doi.org/10.1371/journal.pone.0215240},
    pages = {1-13},
    abstract = {Background The Tuberculin Skin Test (TST) is a relatively simple test for detecting latent tuberculosis infection (LTBI) but requires regular quality assurance to ensure proper technique for administration and reading. The objective of this study was to estimate the accuracy and reproducibility of an mhealth approach (the mTST) to measure the size of swelling immediately following TST administration (TST injection bleb) and after 48–72 hours (TST induration).   Methods Five non-clinical and one clinical reviewer measured the size of TST injection blebs, and TST indurations using smartphone acquired photos of sites of TST administration and readings in patients, or saline injections in volunteers. The reference standard was the onsite measurement (measured by an experienced TB nurse) of the actual TST injection bleb, or induration. Agreement of reviewers’ measurements with the reference standard, as well as agreement within and between reviewers, was estimated using Cohen's kappa coefficient.   Results Using the mTST method to assess bleb size in 64 photos of different TST injections, agreement between reviewers, and the reference standard was very good to excellent (κ ranged from 0.75 to 0.87), and within-reviewer reproducibility of readings was excellent (κ ranged from 0.86 to 0.96). Using the mTST method to assess TST induration in 72 photos, reviewers were able to detect no induration (<5mm) and induration of 15mm or greater with accuracy of 95% and 92% respectively, but accuracy was only 20% and 77% for reactions of 5-9mm and 10-14mm respectively.   Conclusion The mTST approach appears to be a reliable tool to assess TST administration. The mTST approach was accurate to read indurations of 0-4mm or 15+mm, but less accurate for reactions of 5-14mm. We believe the mTST approach could be useful for training and quality assurance in locations where on-site supervision is not possible.},
    number = {4},

}

@Article{info:doi/10.2196/biomedeng.8333,
author="Dendere, Ronald
and Mutsvangwa, Tinashe
and Goliath, Rene
and Rangaka, Molebogeng X
and Abubakar, Ibrahim
and Douglas, Tania S",
title="Measurement of Skin Induration Size Using Smartphone Images and Photogrammetric Reconstruction: Pilot Study",
journal="JMIR Biomed Eng",
year="2017",
month="Dec",
day="07",
volume="2",
number="1",
pages="e3",
keywords="tuberculosis; skin tests; telemedicine; computer assisted diagnosis",
abstract="Background: The tuberculin skin test (TST) is the most common method for detecting latent tuberculosis infection (LTBI). The test requires that a patient return to the health facility or be visited by a health care worker 48 to 72 hours after the intradermal placement of tuberculin so that the size of the resulting skin induration, if any, can be measured. Objective: This study aimed to propose and evaluate an image-based method for measuring induration size from images captured using a smartphone camera. Methods: We imaged simulated skin indurations, ranging from 4.0 to 19 mm, in 10 subjects using a handheld smartphone, and performed three-dimensional reconstruction of the induration sites using photogrammetry software. An experienced TST reader measured the size of each induration using the standard clinical method. The experienced reader and an inexperienced observer both measured the size of each induration using the software. The agreement between measurements generated by the standard clinical and image-based methods was assessed using the intraclass correlation coefficient (ICC). Inter- and intraobserver agreement for the image-based method was similarly evaluated. Results: Results showed excellent agreement between the standard and image-based measurements performed by the experienced reader with an ICC value of .965. Inter- and intraobserver agreements were also excellent, indicating that experience in reading TSTs is not required with our proposed method. Conclusions: We conclude that the proposed smartphone image-based method is a potential alternative to standard induration size measurement and would enable remote data collection for LTBI screening. ",
issn="2561-3278",
doi="10.2196/biomedeng.8333",
url="http://biomedeng.jmir.org/2017/1/e3/",
url="https://doi.org/10.2196/biomedeng.8333"
}




@Article{computers10040043,
AUTHOR = {Ferreira, Filipe and Pires, Ivan Miguel and Costa, Mónica and Ponciano, Vasco and Garcia, Nuno M. and Zdravevski, Eftim and Chorbev, Ivan and Mihajlov, Martin},
TITLE = {A Systematic Investigation of Models for Color Image Processing in Wound Size Estimation},
JOURNAL = {Computers},
VOLUME = {10},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {43},
URL = {https://www.mdpi.com/2073-431X/10/4/43},
ISSN = {2073-431X},
ABSTRACT = {In recent years, research in tracking and assessing wound severity using computerized image processing has increased. With the emergence of mobile devices, powerful functionalities and processing capabilities have provided multiple non-invasive wound evaluation opportunities in both clinical and non-clinical settings. With current imaging technologies, objective and reliable techniques provide qualitative information that can be further processed to provide quantitative information on the size, structure, and color characteristics of wounds. These efficient image analysis algorithms help determine the injury features and the progress of healing in a short time. This paper presents a systematic investigation of articles that specifically address the measurement of wounds’ sizes with image processing techniques, promoting the connection between computer science and health. Of the 208 studies identified by searching electronic databases, 20 were included in the review. From the perspective of image processing color models, the most dominant model was the hue, saturation, and value (HSV) color space. We proposed that a method for measuring the wound area must implement different stages, including conversion to grayscale for further implementation of the threshold and a segmentation method to measure the wound area as the number of pixels for further conversion to metric units. Regarding devices, mobile technology is shown to have reached the level of reliable accuracy.},
DOI = {10.3390/computers10040043}
}


@INPROCEEDINGS{8448729,
  author={Huang, Cheng-Hsien and Jhan, Sing-Da and Lin, Cheng-Hsuan and Liu, Wei-Min},
  booktitle={2018 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW)}, 
  title={Automatic Size Measurement and Boundary Tracing of Wound on a Mobile Device}, 
  year={2018},
  volume={},
  number={},
  pages={1-2},
  keywords={Wounds;Image segmentation;Level set;Image edge detection;Histograms;Mobile handsets;Commercialization},
  doi={10.1109/ICCE-China.2018.8448729}}


@article{SCEBBA2022100884,
title = {Detect-and-segment: A deep learning approach to automate wound image segmentation},
journal = {Informatics in Medicine Unlocked},
volume = {29},
pages = {100884},
year = {2022},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2022.100884},
url = {https://www.sciencedirect.com/science/article/pii/S2352914822000375},
author = {Gaetano Scebba and Jia Zhang and Sabrina Catanzaro and Carina Mihai and Oliver Distler and Martin Berli and Walter Karlen},
keywords = {Chronic wounds, Semantic segmentation, Machine learning, Generalizability, Smartphone},
abstract = {Chronic wounds significantly impact quality of life. They can rapidly deteriorate and require close monitoring of healing progress. Image-based wound analysis is a way of objectively assessing the wound status by quantifying important features that are related to healing. However, high heterogeneity of the wound types and imaging conditions challenge the robust segmentation of wound images. We present Detect-and-Segment (DS), a deep learning approach to produce wound segmentation maps with high generalization capabilities. In our approach, dedicated deep neural networks detected the wound position, isolated the wound from the perturbing background, and computed a wound segmentation map. We tested this approach on a diabetic foot ulcers data set and compared it to a segmentation method based on the full image. To evaluate its generalizability on out-of-distribution data, we measured the performance of the DS approach on 4 additional independent data sets, with larger variety of wound types from different body locations. The Matthews’ correlation coefficient (MCC) improved from 0.29 (full image) to 0.85 (DS) on the diabetic foot ulcer data set. When the DS was tested on the independent data sets, the mean MCC increased from 0.17 to 0.85 . Furthermore, the DS enabled the training of segmentation models with up to 90% less training data without impacting the segmentation performance. The proposed DS approach is a step towards automating wound analysis and reducing efforts to manage chronic wounds.}
}

@article{BASAK2022108673,
title = {MFSNet: A multi focus segmentation network for skin lesion segmentation},
journal = {Pattern Recognition},
volume = {128},
pages = {108673},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2022.108673},
url = {https://www.sciencedirect.com/science/article/pii/S0031320322001546},
author = {Hritam Basak and Rohit Kundu and Ram Sarkar},
keywords = {Lesion Segmentation, Deep Learning, Parallel Partial Decoder, Attention Modules, Skin Melanoma},
abstract = {Segmentation is essential for medical image analysis to identify and localize diseases, monitor morphological changes, and extract discriminative features for further diagnosis. Skin cancer is one of the most common types of cancer globally, and its early diagnosis is pivotal for the complete elimination of malignant tumors from the body. This research develops an Artificial Intelligence (AI) framework for supervised skin lesion segmentation employing the deep learning approach. The proposed framework, called MFSNet (Multi-Focus Segmentation Network), uses differently scaled feature maps for computing the final segmentation mask using raw input RGB images of skin lesions. In doing so, initially, the images are preprocessed to remove unwanted artifacts and noises. The MFSNet employs the Res2Net backbone, a recently proposed convolutional neural network (CNN), for obtaining deep features used in a Parallel Partial Decoder (PPD) module to get a global map of the segmentation mask. In different stages of the network, convolution features and multi-scale maps are used in two boundary attention (BA) modules and two reverse attention (RA) modules to generate the final segmentation output. MFSNet, when evaluated on three publicly available datasets: PH2, ISIC 2017, and HAM10000, outperforms state-of-the-art methods, justifying the reliability of the framework. The relevant codes for the proposed approach are accessible at https://github.com/Rohit-Kundu/MFSNet.}
}

@article{ZANG2024114409,
title = {Tuberculin skin test result detection method based on CSN-II and improved OTSU method},
journal = {Measurement},
volume = {229},
pages = {114409},
year = {2024},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2024.114409},
url = {https://www.sciencedirect.com/science/article/pii/S026322412400294X},
author = {Junbin Zang and Tianming Cai and Chen Zong and Guang Yang and Zhidong Zhang and Chenyang Xue},
keywords = {Tuberculin test, Image segmentation, Colour space, Image information entropy, Otsu method},
abstract = {The tuberculin skin test (TST) is an intradermal test used to diagnose Type IV hypersensitivity reactions caused by Mycobacterium tuberculosis infection. Segmentation of TST result images provides a foundation for large-scale tuberculosis screening and auxiliary diagnosis. This paper presents a specialized method for identifying TST results. Initially, a clustering approach is employed to reduce pixel complexity, followed by a linear transformation using CSN-II to enhance the original RGB space with robust color space properties. Subsequently, high-probability pixel points are located, and their Gaussian kernel convolution range is determined using the Bhattacharyya Distance. Through convolution and iterative feature amplification, the target characteristics are progressively enhanced. Finally, an improved OTSU method is proposed for segmenting TST result images. In this method, an adaptive entropy threshold is utilized to reduce the search range of the OTSU method, enhancing the relative contrast between the target and the background. Moreover, a weighted adjustment is applied to the obtained OTSU threshold to prevent drift towards backgrounds with larger intra-class variances. Experimental results demonstrate that the proposed method achieves higher segmentation accuracy and robustness in TST result image segmentation compared to traditional OTSU methods and other improved approaches, such as the neighborhood valley-emphasis method, logarithmic OTSU, and weighted OTSU, Finally, we calculate a relative value is calculated by dividing the remaining number of segmented pixels by the total number of pixels, we then classify the results based on the relative value and in reference to medical diagnostic standards our method is intended to establish an algorithmic basis for rapid screening and classification of tuberculosis on a large scale.}
}

@article{NARAGHI201876,
title = {Mobile phone-based evaluation of latent tuberculosis infection: Proof of concept for an integrated image capture and analysis system},
journal = {Computers in Biology and Medicine},
volume = {98},
pages = {76-84},
year = {2018},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2018.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0010482518301161},
author = {Safa Naraghi and Tinashe Mutsvangwa and René Goliath and Molebogeng X. Rangaka and Tania S. Douglas},
keywords = {Tuberculosis, Tuberculin skin test, Mobile phone, Mobile health, mHealth, Photogrammetry},
abstract = {Background
The tuberculin skin test is the most widely used method for detecting latent tuberculosis infection in adults and active tuberculosis in children. We present the development of a mobile-phone based screening tool for measuring the tuberculin skin test induration.
Method
The tool makes use of a mobile application developed on the Android platform to capture images of an induration, and photogrammetric reconstruction using Agisoft PhotoScan to reconstruct the induration in 3D, followed by 3D measurement of the induration with the aid of functions from the Python programming language. The system enables capture of images by the person being screened for latent tuberculosis infection. Measurement precision was tested using a 3D printed induration. Real-world use of the tool was simulated by application to a set of mock skin indurations, created by a make-up artist, and the performance of the tool was evaluated. The usability of the application was assessed with the aid of a questionnaire completed by participants.
Results
The tool was found to measure the 3D printed induration with greater precision than the current ruler and pen method, as indicated by the lower standard deviation produced (0.3 mm versus 1.1 mm in the literature). There was high correlation between manual and algorithm measurement of mock skin indurations. The height of the skin induration and the definition of its margins were found to influence the accuracy of 3D reconstruction and therefore the measurement error, under simulated real-world conditions. Based on assessment of the user experience in capturing images, a simplified user interface would benefit wide-spread implementation.
Conclusions
The mobile application shows good agreement with direct measurement. It provides an alternative method for measuring tuberculin skin test indurations and may remove the need for an in-person follow-up visit after test administration, thus improving latent tuberculosis infection screening throughput.}
}